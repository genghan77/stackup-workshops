# Mask or No-mask?

[![Mask or Not CI](https://github.com/lisaong/stackup-workshops/workflows/Mask%20or%20Not%20CI/badge.svg)](https://github.com/lisaong/stackup-workshops/actions?query=workflow%3A%22Mask+or+Not+CI%22)

## Introduction
TBA

## Instructions
1. Go to `Documents\Arduino\libraries`

   a. Create the subfolder `mask_or_not`, copy the contents of the `model` directory to it. Just copy the *.h, don't copy the models directory.

   b. git clone https://github.com/eloquentarduino/EloquentTinyML
  
2. Start Arduino IDE
3. Open the sketch file: `run_model.ino`
4. Connect an ESP32 to USB, select the COM port to connect to it
5. Upload the sketch to the ESP32
6. Once upload is complete, open Serial Monitor to monitor serial output
  
   a. If you observe `nan`, reset the ESP32 to see if `AllocateTensors` has failed. If so, you may need to increase `TENSOR_ARENA_SIZE`.

   b. If the ESP32 goes into a reboot loop, the PCA input dimensions are too big. Try a smaller image dimension (`OUTPUT_SIZE` in the Colab Notebook).
  
   c. If you get a linker error (dangerous relocation), the PCA input dimensions are too big. Try a smaller image dimension (`OUTPUT_SIZE` in the Colab Notebook).

Sample output from Serial Monitor (using random data):
```
0.76,-0.82,0.45,-0.80,-0.09,-1.00,-0.83,0.15,0.01,-0.35,0.87,-0.46,-0.51,0.18,0.70,0.20,-0.92,0.34,-0.32,-0.64,-0.82,-0.58,-0.65,-0.51,0.13,-0.09,0.21,0.67,0.43,0.35,0.56,-0.22,0.07,0.54,0.80,0.33,0.50,-0.94,-0.02,-0.34,0.30,-0.06,0.83,0.53,-0.24,-0.59,0.20,0.71,0.88,0.55,-0.72,0.48,0.53,-0.76,0.78,-0.85,-0.61,0.92,-0.82,-0.23,-0.71,-0.87,0.42,-0.54,0.83,-0.85,-0.76,0.00,-0.66,0.54,0.82,0.67,0.57,0.97,-0.52,0.00,-0.87,0.50,-0.80,-0.03,-0.43,-0.59,0.15,-0.45,0.76,0.31,-0.85,0.12,0.76,-0.91,-0.09,-0.75,-0.54,-0.94,-0.75,0.71,0.02,0.24,-0.93,0.69,0.65,-0.76,-0.54,0.94,-0.80,-0.98,0.83,0.66,-0.36,-0.10,-0.40,0.80,0.90,-0.82,0.26,0.78,0.62,-0.57,0.01,-0.98,0.32,0.63,0.23,-0.28,0.36,-0.05,0.54,0.36,-0.18,-0.83,-0.80,-0.21,0.28,0.57,-0.17,0.04,-0.18,0.90,-0.78,0.08,-0.94,0.76,-0.15,-0.32,0.52,-0.66,0.94,-0.33,-0.47,-0.38,-0.28,-0.65,-0.72,-0.84,0.26,0.13,0.57,-0.98,-0.27,0.29,0.75,-0.73,0.57,0.37,-1.00,-0.02,-0.29,0.82,0.97,-0.52,-0.72,0.13,-0.72,0.86,0.98,-0.32,-0.60,-0.17,-0.46,0.98,-0.87,0.20,0.94,-0.01,-0.95,0.85,-0.08,-0.02,-0.46,0.72,0.91,0.04,0.73,-0.09,-0.11,0.14,0.85,0.86,0.27,-0.43,-0.63,0.70,0.51,-0.28,-0.23,0.24,-0.23,-0.24,0.24,-0.58,0.88,-0.81,0.63,-0.50,-0.57,0.42,-0.06,-0.49,-0.44,-0.27,0.96,0.56,0.99,0.51,-0.81,0.07,-0.84,0.41,-0.93,-0.07,-0.93,-0.62,0.69,-0.97,0.73,0.57,0.24,-0.93,-0.89,0.92,-0.12,-0.17,-0.12,0.83,0.51,-0.21,0.08,0.46,0.88,0.00,0.54,-0.06,-0.76,-0.90,-0.69,-0.96,-0.81,-0.49,-0.70,0.10,-0.86,-0.24,0.05,-0.68,-0.59,0.66,-0.80,0.60,0.10,-0.67,0.12,0.69,0.56,-0.57,0.29,0.81,0.10,-0.74,0.05,0.68,-0.06,0.44,-0.39,-0.03,0.43,-0.27,-0.39,-0.91,0.35,-0.25,0.46,-0.94,-0.20,-0.62,-0.98,-0.76,0.58,0.25,0.42,-0.20,-0.72,0.85,-0.17,-0.75,-0.28,0.66,-0.16,0.09,0.76,0.46,-0.17,-0.79,0.46,-0.38,-0.12,0.52,0.82,-0.29,0.75,-0.31,-0.52,0.70,-0.72,-0.24,-0.48,-0.32,0.15,0.62,0.39,-0.46,-0.47,-0.62,-0.31,0.72,0.02,0.88,0.91,-0.65,0.54,-0.16,0.42,0.06,-0.39,0.69,-0.94,0.22,-0.52,0.32,-0.57,0.94,0.63,-0.35,0.69,0.35,0.06,0.76,0.06,0.73,0.45,-0.86,-0.28,-0.88,-0.68,-0.58,0.43,0.02,-0.66,0.29,0.86,-0.80,-0.06,-0.50,0.77,-0.76,-0.07,-0.58,0.69,-0.69,0.49,-0.83,0.54,-0.20,-0.98,-0.83,0.50,-0.27,-0.87,0.23,0.72,-0.52,0.74,-0.80,-0.88,0.87,0.98,-0.59,0.63,0.23,0.09,0.54,
transforming...
predicting...
predicted: 0.57
-0.54,-0.19,0.55,0.26,-0.13,0.96,0.95,-0.68,0.74,-0.79,-0.46,0.21,-0.67,-0.86,0.71,-1.00,0.29,-0.86,0.39,0.61,0.91,0.35,-0.88,-0.89,0.76,-0.91,-0.11,0.20,-0.17,0.35,0.77,0.07,-0.73,0.37,-0.92,0.34,-0.72,-0.29,0.76,-0.40,0.45,-0.99,0.51,0.89,0.70,-0.10,0.19,-0.36,-0.35,0.42,0.25,-0.33,0.50,-0.46,0.37,-0.09,0.11,-0.02,0.11,0.80,0.38,0.41,-0.89,-0.23,-0.38,-0.67,-0.64,0.57,-0.35,0.72,-0.73,-0.26,0.13,-0.51,0.27,0.13,-0.81,-0.43,0.82,0.14,0.19,-0.13,0.40,-0.87,-0.35,0.01,-0.74,-0.96,-0.26,0.31,-0.57,0.53,-0.08,0.76,-0.58,-0.42,-0.17,-0.17,-0.90,0.51,0.66,0.18,-0.42,0.31,0.66,-0.87,0.36,-0.79,0.70,0.69,-0.37,-0.63,0.50,0.44,-0.47,-0.66,-0.35,-0.17,0.50,0.81,-0.54,0.05,0.27,0.14,0.76,0.25,0.25,0.37,-0.17,-0.17,0.12,0.41,0.60,-0.54,0.70,0.72,-0.14,-0.21,-0.80,0.23,-0.91,-0.98,0.81,0.94,0.78,0.97,-0.41,-0.35,0.72,-0.53,-0.04,-0.23,0.05,0.78,-0.55,0.02,-0.53,0.90,0.55,0.33,0.80,0.63,-0.86,-0.13,0.40,0.76,0.63,0.79,-0.80,0.80,-0.69,-0.78,-0.65,-0.93,0.69,0.72,-0.87,0.61,-0.41,-0.95,0.98,0.91,0.78,-0.39,-0.98,-0.98,-0.31,0.68,0.68,0.44,0.94,-0.24,-0.06,0.53,-0.85,0.96,0.77,0.69,0.49,0.60,-0.83,-0.29,-0.28,-0.81,-0.32,0.94,-0.76,-0.36,0.56,0.96,0.28,0.34,-0.89,0.72,-0.31,-0.94,0.64,0.91,-0.53,-0.80,0.94,-0.49,0.09,-0.24,-0.61,-0.19,0.39,-0.21,0.50,0.68,0.66,-0.18,0.74,0.54,0.14,0.13,0.83,-0.24,0.23,-0.31,-0.95,0.21,-0.71,-0.87,0.87,0.23,0.94,-0.80,0.61,0.25,0.69,0.05,0.07,-0.94,0.93,0.57,0.86,-0.54,0.07,0.46,0.09,0.68,-0.71,-0.41,-0.30,-0.76,0.50,0.15,0.24,0.54,0.87,0.39,0.62,0.05,-0.84,0.14,-0.94,0.33,-0.34,-0.61,0.01,0.17,-0.40,0.91,0.29,0.52,-0.73,0.63,-1.00,-0.46,-0.24,0.51,0.19,0.73,0.61,0.91,0.43,0.06,-0.57,0.78,-0.19,0.01,-0.65,-0.09,-0.16,-0.76,0.10,-0.68,-0.01,0.72,0.13,0.69,0.95,-0.13,-0.87,0.57,0.77,0.23,-0.28,0.12,-0.77,-0.56,0.19,-0.72,-0.70,-0.72,-0.80,-0.89,-0.19,0.52,0.87,0.69,0.55,0.92,0.35,-0.05,0.02,0.87,0.31,-0.94,0.62,-0.90,0.06,0.83,-0.89,-0.85,-0.20,-0.99,-0.62,0.07,0.27,-0.28,-0.18,-0.79,0.87,-0.51,0.63,-0.31,-0.16,-0.29,-0.61,-0.10,-0.63,0.14,0.21,0.54,0.06,-0.13,-0.13,0.59,0.13,-0.77,-0.13,-0.37,0.56,0.04,-0.49,0.25,-0.20,-0.91,-0.70,0.17,-0.55,0.67,0.51,0.67,0.28,0.32,-0.96,-0.45,-0.11,0.13,-0.93,-0.72,-0.98,-0.25,0.16,-0.22,-0.35,0.44,
transforming...
predicting...
predicted: 0.47
```

View the [Colab Notebook](mask_or_not.ipynb).
